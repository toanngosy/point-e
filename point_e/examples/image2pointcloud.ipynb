{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from point_e.diffusion.configs import DIFFUSION_CONFIGS, diffusion_from_config\n",
    "from point_e.diffusion.sampler import PointCloudSampler\n",
    "from point_e.models.download import load_checkpoint\n",
    "from point_e.models.configs import MODEL_CONFIGS, model_from_config\n",
    "from point_e.util.plotting import plot_point_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating base model...\n",
      "creating upsample model...\n",
      "downloading base checkpoint...\n",
      "downloading upsampler checkpoint...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('creating base model...')\n",
    "base_name = 'base1B' #'base40M' # use base300M or base1B for better results\n",
    "base_model = model_from_config(MODEL_CONFIGS[base_name], device)\n",
    "base_model.eval()\n",
    "base_diffusion = diffusion_from_config(DIFFUSION_CONFIGS[base_name])\n",
    "\n",
    "print('creating upsample model...')\n",
    "upsampler_model = model_from_config(MODEL_CONFIGS['upsample'], device)\n",
    "upsampler_model.eval()\n",
    "upsampler_diffusion = diffusion_from_config(DIFFUSION_CONFIGS['upsample'])\n",
    "\n",
    "print('downloading base checkpoint...')\n",
    "base_model.load_state_dict(load_checkpoint(base_name, device))\n",
    "\n",
    "print('downloading upsampler checkpoint...')\n",
    "upsampler_model.load_state_dict(load_checkpoint('upsample', device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = PointCloudSampler(\n",
    "    device=device,\n",
    "    models=[base_model, upsampler_model],\n",
    "    diffusions=[base_diffusion, upsampler_diffusion],\n",
    "    num_points=[1024, 4096 - 1024],\n",
    "    aux_channels=['R', 'G', 'B'],\n",
    "    guidance_scale=[3.0, 3.0],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULL RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image to condition on.\n",
    "# img = Image.open('example_data/cube_stack.jpg')\n",
    "from pathlib import Path\n",
    "file_paths = [file_path for file_path in Path('firework_example_data/30-ts-2_serpent').glob('*.png')]\n",
    "\n",
    "for path in file_paths:\n",
    "    img = Image.open(str(path))\n",
    "\n",
    "    # Produce a sample from the model.\n",
    "    samples = None\n",
    "    for x in tqdm(sampler.sample_batch_progressive(batch_size=1, model_kwargs=dict(images=[img]))):\n",
    "        samples = x\n",
    "    pc = sampler.output_to_point_clouds(samples)[0]\n",
    "    pc.save(f'firework_example_data/pc_{path.stem}.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINGLE RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image to condition on.\n",
    "# img = Image.open('example_data/cube_stack.jpg')\n",
    "from pathlib import Path\n",
    "path = Path('firework_example_data/30-ts-2_serpent/012.png')\n",
    "\n",
    "img = Image.open(str(path))\n",
    "\n",
    "# Produce a sample from the model.\n",
    "samples = None\n",
    "for x in tqdm(sampler.sample_batch_progressive(batch_size=1, model_kwargs=dict(images=[img]))):\n",
    "    samples = x\n",
    "pc = sampler.output_to_point_clouds(samples)[0]\n",
    "pc.save(f'firework_example_data/pc_{path.stem}.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = sampler.output_to_point_clouds(samples)[0]\n",
    "fig = plot_point_cloud(pc, grid_size=3, fixed_bounds=((-0.75, -0.75, -0.75),(0.75, 0.75, 0.75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.save('example_data/pc_012.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check out pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from point_e.util.point_cloud import PointCloud\n",
    "pc = PointCloud.load('example_data/pc_012.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "/* Put everything inside the global mpl namespace */\n/* global mpl */\nwindow.mpl = {};\n\nmpl.get_websocket_type = function () {\n    if (typeof WebSocket !== 'undefined') {\n        return WebSocket;\n    } else if (typeof MozWebSocket !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert(\n            'Your browser does not have WebSocket support. ' +\n                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n                'Firefox 4 and 5 are also supported but you ' +\n                'have to enable WebSockets in about:config.'\n        );\n    }\n};\n\nmpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = this.ws.binaryType !== undefined;\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById('mpl-warnings');\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent =\n                'This browser does not support binary websocket messages. ' +\n                'Performance may be slow.';\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = document.createElement('div');\n    this.root.setAttribute('style', 'display: inline-block');\n    this._root_extra_style(this.root);\n\n    parent_element.appendChild(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen = function () {\n        fig.send_message('supports_binary', { value: fig.supports_binary });\n        fig.send_message('send_image_mode', {});\n        if (fig.ratio !== 1) {\n            fig.send_message('set_device_pixel_ratio', {\n                device_pixel_ratio: fig.ratio,\n            });\n        }\n        fig.send_message('refresh', {});\n    };\n\n    this.imageObj.onload = function () {\n        if (fig.image_mode === 'full') {\n            // Full images could contain transparency (where diff images\n            // almost always do), so we need to clear the canvas so that\n            // there is no ghosting.\n            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n        }\n        fig.context.drawImage(fig.imageObj, 0, 0);\n    };\n\n    this.imageObj.onunload = function () {\n        fig.ws.close();\n    };\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n};\n\nmpl.figure.prototype._init_header = function () {\n    var titlebar = document.createElement('div');\n    titlebar.classList =\n        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n    var titletext = document.createElement('div');\n    titletext.classList = 'ui-dialog-title';\n    titletext.setAttribute(\n        'style',\n        'width: 100%; text-align: center; padding: 3px;'\n    );\n    titlebar.appendChild(titletext);\n    this.root.appendChild(titlebar);\n    this.header = titletext;\n};\n\nmpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._init_canvas = function () {\n    var fig = this;\n\n    var canvas_div = (this.canvas_div = document.createElement('div'));\n    canvas_div.setAttribute('tabindex', '0');\n    canvas_div.setAttribute(\n        'style',\n        'border: 1px solid #ddd;' +\n            'box-sizing: content-box;' +\n            'clear: both;' +\n            'min-height: 1px;' +\n            'min-width: 1px;' +\n            'outline: 0;' +\n            'overflow: hidden;' +\n            'position: relative;' +\n            'resize: both;' +\n            'z-index: 2;'\n    );\n\n    function on_keyboard_event_closure(name) {\n        return function (event) {\n            return fig.key_event(event, name);\n        };\n    }\n\n    canvas_div.addEventListener(\n        'keydown',\n        on_keyboard_event_closure('key_press')\n    );\n    canvas_div.addEventListener(\n        'keyup',\n        on_keyboard_event_closure('key_release')\n    );\n\n    this._canvas_extra_style(canvas_div);\n    this.root.appendChild(canvas_div);\n\n    var canvas = (this.canvas = document.createElement('canvas'));\n    canvas.classList.add('mpl-canvas');\n    canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'pointer-events: none;' +\n            'position: relative;' +\n            'z-index: 0;'\n    );\n\n    this.context = canvas.getContext('2d');\n\n    var backingStore =\n        this.context.backingStorePixelRatio ||\n        this.context.webkitBackingStorePixelRatio ||\n        this.context.mozBackingStorePixelRatio ||\n        this.context.msBackingStorePixelRatio ||\n        this.context.oBackingStorePixelRatio ||\n        this.context.backingStorePixelRatio ||\n        1;\n\n    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n        'canvas'\n    ));\n    rubberband_canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'left: 0;' +\n            'pointer-events: none;' +\n            'position: absolute;' +\n            'top: 0;' +\n            'z-index: 1;'\n    );\n\n    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n    if (this.ResizeObserver === undefined) {\n        if (window.ResizeObserver !== undefined) {\n            this.ResizeObserver = window.ResizeObserver;\n        } else {\n            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n            this.ResizeObserver = obs.ResizeObserver;\n        }\n    }\n\n    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n        var nentries = entries.length;\n        for (var i = 0; i < nentries; i++) {\n            var entry = entries[i];\n            var width, height;\n            if (entry.contentBoxSize) {\n                if (entry.contentBoxSize instanceof Array) {\n                    // Chrome 84 implements new version of spec.\n                    width = entry.contentBoxSize[0].inlineSize;\n                    height = entry.contentBoxSize[0].blockSize;\n                } else {\n                    // Firefox implements old version of spec.\n                    width = entry.contentBoxSize.inlineSize;\n                    height = entry.contentBoxSize.blockSize;\n                }\n            } else {\n                // Chrome <84 implements even older version of spec.\n                width = entry.contentRect.width;\n                height = entry.contentRect.height;\n            }\n\n            // Keep the size of the canvas and rubber band canvas in sync with\n            // the canvas container.\n            if (entry.devicePixelContentBoxSize) {\n                // Chrome 84 implements new version of spec.\n                canvas.setAttribute(\n                    'width',\n                    entry.devicePixelContentBoxSize[0].inlineSize\n                );\n                canvas.setAttribute(\n                    'height',\n                    entry.devicePixelContentBoxSize[0].blockSize\n                );\n            } else {\n                canvas.setAttribute('width', width * fig.ratio);\n                canvas.setAttribute('height', height * fig.ratio);\n            }\n            /* This rescales the canvas back to display pixels, so that it\n             * appears correct on HiDPI screens. */\n            canvas.style.width = width + 'px';\n            canvas.style.height = height + 'px';\n\n            rubberband_canvas.setAttribute('width', width);\n            rubberband_canvas.setAttribute('height', height);\n\n            // And update the size in Python. We ignore the initial 0/0 size\n            // that occurs as the element is placed into the DOM, which should\n            // otherwise not happen due to the minimum size styling.\n            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n                fig.request_resize(width, height);\n            }\n        }\n    });\n    this.resizeObserverInstance.observe(canvas_div);\n\n    function on_mouse_event_closure(name) {\n        /* User Agent sniffing is bad, but WebKit is busted:\n         * https://bugs.webkit.org/show_bug.cgi?id=144526\n         * https://bugs.webkit.org/show_bug.cgi?id=181818\n         * The worst that happens here is that they get an extra browser\n         * selection when dragging, if this check fails to catch them.\n         */\n        var UA = navigator.userAgent;\n        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n        if(isWebKit) {\n            return function (event) {\n                /* This prevents the web browser from automatically changing to\n                 * the text insertion cursor when the button is pressed. We\n                 * want to control all of the cursor setting manually through\n                 * the 'cursor' event from matplotlib */\n                event.preventDefault()\n                return fig.mouse_event(event, name);\n            };\n        } else {\n            return function (event) {\n                return fig.mouse_event(event, name);\n            };\n        }\n    }\n\n    canvas_div.addEventListener(\n        'mousedown',\n        on_mouse_event_closure('button_press')\n    );\n    canvas_div.addEventListener(\n        'mouseup',\n        on_mouse_event_closure('button_release')\n    );\n    canvas_div.addEventListener(\n        'dblclick',\n        on_mouse_event_closure('dblclick')\n    );\n    // Throttle sequential mouse events to 1 every 20ms.\n    canvas_div.addEventListener(\n        'mousemove',\n        on_mouse_event_closure('motion_notify')\n    );\n\n    canvas_div.addEventListener(\n        'mouseenter',\n        on_mouse_event_closure('figure_enter')\n    );\n    canvas_div.addEventListener(\n        'mouseleave',\n        on_mouse_event_closure('figure_leave')\n    );\n\n    canvas_div.addEventListener('wheel', function (event) {\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        on_mouse_event_closure('scroll')(event);\n    });\n\n    canvas_div.appendChild(canvas);\n    canvas_div.appendChild(rubberband_canvas);\n\n    this.rubberband_context = rubberband_canvas.getContext('2d');\n    this.rubberband_context.strokeStyle = '#000000';\n\n    this._resize_canvas = function (width, height, forward) {\n        if (forward) {\n            canvas_div.style.width = width + 'px';\n            canvas_div.style.height = height + 'px';\n        }\n    };\n\n    // Disable right mouse context menu.\n    canvas_div.addEventListener('contextmenu', function (_e) {\n        event.preventDefault();\n        return false;\n    });\n\n    function set_focus() {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'mpl-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'mpl-button-group';\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'mpl-button-group';\n            continue;\n        }\n\n        var button = (fig.buttons[name] = document.createElement('button'));\n        button.classList = 'mpl-widget';\n        button.setAttribute('role', 'button');\n        button.setAttribute('aria-disabled', 'false');\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n\n        var icon_img = document.createElement('img');\n        icon_img.src = '_images/' + image + '.png';\n        icon_img.srcset = '_images/' + image + '_large.png 2x';\n        icon_img.alt = tooltip;\n        button.appendChild(icon_img);\n\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    var fmt_picker = document.createElement('select');\n    fmt_picker.classList = 'mpl-widget';\n    toolbar.appendChild(fmt_picker);\n    this.format_dropdown = fmt_picker;\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = document.createElement('option');\n        option.selected = fmt === mpl.default_extension;\n        option.innerHTML = fmt;\n        fmt_picker.appendChild(option);\n    }\n\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n};\n\nmpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', { width: x_pixels, height: y_pixels });\n};\n\nmpl.figure.prototype.send_message = function (type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n};\n\nmpl.figure.prototype.send_draw_message = function () {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n};\n\nmpl.figure.prototype.handle_resize = function (fig, msg) {\n    var size = msg['size'];\n    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1], msg['forward']);\n        fig.send_message('refresh', {});\n    }\n};\n\nmpl.figure.prototype.handle_rubberband = function (fig, msg) {\n    var x0 = msg['x0'] / fig.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n    var x1 = msg['x1'] / fig.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0,\n        0,\n        fig.canvas.width / fig.ratio,\n        fig.canvas.height / fig.ratio\n    );\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n};\n\nmpl.figure.prototype.handle_figure_label = function (fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n};\n\nmpl.figure.prototype.handle_cursor = function (fig, msg) {\n    fig.canvas_div.style.cursor = msg['cursor'];\n};\n\nmpl.figure.prototype.handle_message = function (fig, msg) {\n    fig.message.textContent = msg['message'];\n};\n\nmpl.figure.prototype.handle_draw = function (fig, _msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n};\n\nmpl.figure.prototype.handle_image_mode = function (fig, msg) {\n    fig.image_mode = msg['mode'];\n};\n\nmpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n    for (var key in msg) {\n        if (!(key in fig.buttons)) {\n            continue;\n        }\n        fig.buttons[key].disabled = !msg[key];\n        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n    }\n};\n\nmpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n    if (msg['mode'] === 'PAN') {\n        fig.buttons['Pan'].classList.add('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    } else if (msg['mode'] === 'ZOOM') {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.add('active');\n    } else {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    }\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Called whenever the canvas gets updated.\n    this.send_message('ack', {});\n};\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function (fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            var img = evt.data;\n            if (img.type !== 'image/png') {\n                /* FIXME: We get \"Resource interpreted as Image but\n                 * transferred with MIME type text/plain:\" errors on\n                 * Chrome.  But how to set the MIME type?  It doesn't seem\n                 * to be part of the websocket stream */\n                img.type = 'image/png';\n            }\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src\n                );\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                img\n            );\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        } else if (\n            typeof evt.data === 'string' &&\n            evt.data.slice(0, 21) === 'data:image/png;base64'\n        ) {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig['handle_' + msg_type];\n        } catch (e) {\n            console.log(\n                \"No handler for the '\" + msg_type + \"' message type: \",\n                msg\n            );\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\n                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n                    e,\n                    e.stack,\n                    msg\n                );\n            }\n        }\n    };\n};\n\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * https://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys(original) {\n    return Object.keys(original).reduce(function (obj, key) {\n        if (typeof original[key] !== 'object') {\n            obj[key] = original[key];\n        }\n        return obj;\n    }, {});\n}\n\nmpl.figure.prototype.mouse_event = function (event, name) {\n    if (name === 'button_press') {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    // from https://stackoverflow.com/q/1114465\n    var boundingRect = this.canvas.getBoundingClientRect();\n    var x = (event.clientX - boundingRect.left) * this.ratio;\n    var y = (event.clientY - boundingRect.top) * this.ratio;\n\n    this.send_message(name, {\n        x: x,\n        y: y,\n        button: event.button,\n        step: event.step,\n        guiEvent: simpleKeys(event),\n    });\n\n    return false;\n};\n\nmpl.figure.prototype._key_event_extra = function (_event, _name) {\n    // Handle any extra behaviour associated with a key event\n};\n\nmpl.figure.prototype.key_event = function (event, name) {\n    // Prevent repeat events\n    if (name === 'key_press') {\n        if (event.key === this._key) {\n            return;\n        } else {\n            this._key = event.key;\n        }\n    }\n    if (name === 'key_release') {\n        this._key = null;\n    }\n\n    var value = '';\n    if (event.ctrlKey && event.key !== 'Control') {\n        value += 'ctrl+';\n    }\n    else if (event.altKey && event.key !== 'Alt') {\n        value += 'alt+';\n    }\n    else if (event.shiftKey && event.key !== 'Shift') {\n        value += 'shift+';\n    }\n\n    value += 'k' + event.key;\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n    return false;\n};\n\nmpl.figure.prototype.toolbar_button_onclick = function (name) {\n    if (name === 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message('toolbar_button', { name: name });\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n    this.message.textContent = tooltip;\n};\n\n///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n// prettier-ignore\nvar _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n\nmpl.default_extension = \"png\";/* global mpl */\n\nvar comm_websocket_adapter = function (comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.binaryType = comm.kernel.ws.binaryType;\n    ws.readyState = comm.kernel.ws.readyState;\n    function updateReadyState(_event) {\n        if (comm.kernel.ws) {\n            ws.readyState = comm.kernel.ws.readyState;\n        } else {\n            ws.readyState = 3; // Closed state.\n        }\n    }\n    comm.kernel.ws.addEventListener('open', updateReadyState);\n    comm.kernel.ws.addEventListener('close', updateReadyState);\n    comm.kernel.ws.addEventListener('error', updateReadyState);\n\n    ws.close = function () {\n        comm.close();\n    };\n    ws.send = function (m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function (msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        var data = msg['content']['data'];\n        if (data['blob'] !== undefined) {\n            data = {\n                data: new Blob(msg['buffers'], { type: data['blob'] }),\n            };\n        }\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(data);\n    });\n    return ws;\n};\n\nmpl.mpl_figure_comm = function (comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = document.getElementById(id);\n    var ws_proxy = comm_websocket_adapter(comm);\n\n    function ondownload(figure, _format) {\n        window.open(figure.canvas.toDataURL());\n    }\n\n    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element;\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error('Failed to find cell for figure', id, fig);\n        return;\n    }\n    fig.cell_info[0].output_area.element.on(\n        'cleared',\n        { fig: fig },\n        fig._remove_fig_handler\n    );\n};\n\nmpl.figure.prototype.handle_close = function (fig, msg) {\n    var width = fig.canvas.width / fig.ratio;\n    fig.cell_info[0].output_area.element.off(\n        'cleared',\n        fig._remove_fig_handler\n    );\n    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable();\n    fig.parent_element.innerHTML =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n    fig.close_ws(fig, msg);\n};\n\nmpl.figure.prototype.close_ws = function (fig, msg) {\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n};\n\nmpl.figure.prototype.push_to_output = function (_remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width / this.ratio;\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message('ack', {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () {\n        fig.push_to_output();\n    }, 1000);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'btn-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'btn-group';\n    var button;\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'btn-group';\n            continue;\n        }\n\n        button = fig.buttons[name] = document.createElement('button');\n        button.classList = 'btn btn-default';\n        button.href = '#';\n        button.title = name;\n        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    // Add the status bar.\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message pull-right';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n\n    // Add the close button to the window.\n    var buttongrp = document.createElement('div');\n    buttongrp.classList = 'btn-group inline pull-right';\n    button = document.createElement('button');\n    button.classList = 'btn btn-mini btn-primary';\n    button.href = '#';\n    button.title = 'Stop Interaction';\n    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n    button.addEventListener('click', function (_evt) {\n        fig.handle_close(fig, {});\n    });\n    button.addEventListener(\n        'mouseover',\n        on_mouseover_closure('Stop Interaction')\n    );\n    buttongrp.appendChild(button);\n    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n};\n\nmpl.figure.prototype._remove_fig_handler = function (event) {\n    var fig = event.data.fig;\n    if (event.target !== this) {\n        // Ignore bubbled events from children.\n        return;\n    }\n    fig.close_ws(fig, {});\n};\n\nmpl.figure.prototype._root_extra_style = function (el) {\n    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n};\n\nmpl.figure.prototype._canvas_extra_style = function (el) {\n    // this is important to make the div 'focusable\n    el.setAttribute('tabindex', 0);\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    } else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n};\n\nmpl.figure.prototype._key_event_extra = function (event, _name) {\n    // Check for shift+enter\n    if (event.shiftKey && event.which === 13) {\n        this.canvas_div.blur();\n        // select the cell after this one\n        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n        IPython.notebook.select(index + 1);\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    fig.ondownload(fig, null);\n};\n\nmpl.find_output_cell = function (html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i = 0; i < ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code') {\n            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] === html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n};\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel !== null) {\n    IPython.notebook.kernel.comm_manager.register_target(\n        'matplotlib',\n        mpl.mpl_figure_comm\n    );\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='58300ea6-2837-450c-9f3a-ac34fff3831c'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "fixed_bounds = ((-0.75, -0.75, -0.75),\n",
    "                (0.75, 0.75, 0.75))\n",
    "color = True\n",
    "\n",
    "sns.set(style = \"darkgrid\")\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "color_args = {}\n",
    "if color:\n",
    "    color_args[\"c\"] = np.stack(\n",
    "        [pc.channels[\"R\"], pc.channels[\"G\"], pc.channels[\"B\"]], axis=-1\n",
    "    )\n",
    "c = pc.coords\n",
    "\n",
    "ax.scatter(c[:, 0], c[:, 1], c[:, 2], **color_args)\n",
    "\n",
    "ax.set_xlim3d(fixed_bounds[0][0], fixed_bounds[1][0])\n",
    "ax.set_ylim3d(fixed_bounds[0][1], fixed_bounds[1][1])\n",
    "ax.set_zlim3d(fixed_bounds[0][2], fixed_bounds[1][2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from point_e.util.point_cloud import PointCloud\n",
    "import torch\n",
    "import kaolin\n",
    "\n",
    "# arguments and hyperparameters\n",
    "device = 'cuda'\n",
    "lr = 1e-3\n",
    "laplacian_weight = 0.8\n",
    "iterations = 10000\n",
    "save_every = 100\n",
    "multires = 8\n",
    "grid_res = 128\n",
    "\n",
    "pc_data = 'example_data/pc_012.npz'\n",
    "#pc_data = 'example_data/pc_corgi.npz'\n",
    "pc = PointCloud.load(pc_data)\n",
    "points = pc.coords\n",
    "#pcd_path = \"/home/ubuntu/point-e/point_e/util/dmtet/usd/bear_pointcloud.usd\"\n",
    "#points = kaolin.io.usd.import_pointclouds(pcd_path)[0].points.to(device)\n",
    "\n",
    "center = (points.max(0)[0] + points.min(0)[0]) / 2\n",
    "max_l = (points.max(0)[0] - points.min(0)[0]).max()\n",
    "points = ((points - center) / max_l)* 0.9\n",
    "points = torch.tensor(points).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2702681/4210860135.py:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  tets = torch.tensor(([np.load('/home/ubuntu/point-e/point_e/util/dmtet/samples/{}_tets_{}.npz'.format(grid_res, i))['data'] for i in range(4)]), dtype=torch.long, device=device).permute(1,0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([277410, 3]) torch.Size([1524684, 4])\n",
      "Initialize SDF to sphere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 403.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained MLP 9.816072270041332e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from point_e.util.dmtet.dmtet_network import Decoder\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "tet_verts = torch.tensor(np.load('/home/ubuntu/point-e/point_e/util/dmtet/samples/{}_verts.npz'.format(grid_res))['data'], dtype=torch.float, device=device)\n",
    "tets = torch.tensor(([np.load('/home/ubuntu/point-e/point_e/util/dmtet/samples/{}_tets_{}.npz'.format(grid_res, i))['data'] for i in range(4)]), dtype=torch.long, device=device).permute(1,0)\n",
    "print(tet_verts.shape, tets.shape)\n",
    "\n",
    "# Initialize model and create optimizer\n",
    "model = Decoder(multires=multires).to(device)\n",
    "model.pre_train_sphere(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian regularization using umbrella operator (Fujiwara / Desbrun).\n",
    "# https://mgarland.org/class/geom04/material/smoothing.pdf\n",
    "import kaolin\n",
    "\n",
    "def laplace_regularizer_const(mesh_verts, mesh_faces):\n",
    "    term = torch.zeros_like(mesh_verts)\n",
    "    norm = torch.zeros_like(mesh_verts[..., 0:1])\n",
    "\n",
    "    v0 = mesh_verts[mesh_faces[:, 0], :]\n",
    "    v1 = mesh_verts[mesh_faces[:, 1], :]\n",
    "    v2 = mesh_verts[mesh_faces[:, 2], :]\n",
    "\n",
    "    term.scatter_add_(0, mesh_faces[:, 0:1].repeat(1,3), (v1 - v0) + (v2 - v0))\n",
    "    term.scatter_add_(0, mesh_faces[:, 1:2].repeat(1,3), (v0 - v1) + (v2 - v1))\n",
    "    term.scatter_add_(0, mesh_faces[:, 2:3].repeat(1,3), (v0 - v2) + (v1 - v2))\n",
    "\n",
    "    two = torch.ones_like(v0) * 2.0\n",
    "    norm.scatter_add_(0, mesh_faces[:, 0:1], two)\n",
    "    norm.scatter_add_(0, mesh_faces[:, 1:2], two)\n",
    "    norm.scatter_add_(0, mesh_faces[:, 2:3], two)\n",
    "\n",
    "    term = term / torch.clamp(norm, min=1.0)\n",
    "\n",
    "    return torch.mean(term**2)\n",
    "\n",
    "def loss_f(mesh_verts, mesh_faces, points, it):\n",
    "    pred_points = kaolin.ops.mesh.sample_points(mesh_verts.unsqueeze(0), mesh_faces, 50000)[0][0]\n",
    "    chamfer = kaolin.metrics.pointcloud.chamfer_distance(pred_points.unsqueeze(0), points.unsqueeze(0)).mean()\n",
    "    if it > iterations//2:\n",
    "        lap = laplace_regularizer_const(mesh_verts, mesh_faces)\n",
    "        return chamfer + lap * laplacian_weight\n",
    "    return chamfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [p for _, p in model.named_parameters()]\n",
    "optimizer = torch.optim.Adam(vars, lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = './logs'\n",
    "\n",
    "# We initialize the timelapse that will store USD for the visualization apps\n",
    "timelapse = kaolin.visualize.Timelapse(logs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 - loss: 0.039039406925439835, # of mesh vertices: 25728, # of mesh faces: 51444\n",
      "Iteration 100 - loss: 0.005376047920435667, # of mesh vertices: 60715, # of mesh faces: 119768\n",
      "Iteration 200 - loss: 0.06702491641044617, # of mesh vertices: 365881, # of mesh faces: 725873\n",
      "Iteration 300 - loss: 0.07136605679988861, # of mesh vertices: 347702, # of mesh faces: 684706\n",
      "Iteration 400 - loss: 0.006381798069924116, # of mesh vertices: 64075, # of mesh faces: 127338\n",
      "Iteration 500 - loss: 0.0027827471494674683, # of mesh vertices: 43988, # of mesh faces: 87634\n",
      "Iteration 600 - loss: 0.0016419888706877828, # of mesh vertices: 42951, # of mesh faces: 85750\n",
      "Iteration 700 - loss: 0.0006066123605705798, # of mesh vertices: 30706, # of mesh faces: 61458\n",
      "Iteration 800 - loss: 0.0006712912581861019, # of mesh vertices: 31250, # of mesh faces: 62560\n",
      "Iteration 900 - loss: 0.000875496247317642, # of mesh vertices: 34092, # of mesh faces: 68053\n",
      "Iteration 1000 - loss: 0.0007283350569196045, # of mesh vertices: 31177, # of mesh faces: 62456\n",
      "Iteration 1100 - loss: 0.0005721490015275776, # of mesh vertices: 26332, # of mesh faces: 52650\n",
      "Iteration 1200 - loss: 0.0009952423861250281, # of mesh vertices: 31639, # of mesh faces: 63264\n",
      "Iteration 1300 - loss: 0.0008437263895757496, # of mesh vertices: 26014, # of mesh faces: 51850\n",
      "Iteration 1400 - loss: 0.0008510776096954942, # of mesh vertices: 23782, # of mesh faces: 47240\n",
      "Iteration 1500 - loss: 0.0010743472957983613, # of mesh vertices: 31958, # of mesh faces: 64004\n",
      "Iteration 1600 - loss: 0.001064816489815712, # of mesh vertices: 31053, # of mesh faces: 62246\n",
      "Iteration 1700 - loss: 0.0009818747639656067, # of mesh vertices: 29450, # of mesh faces: 58904\n",
      "Iteration 1800 - loss: 0.00097821862436831, # of mesh vertices: 31032, # of mesh faces: 62158\n",
      "Iteration 1900 - loss: 0.0010361273307353258, # of mesh vertices: 30864, # of mesh faces: 61864\n",
      "Iteration 2000 - loss: 0.0009597972384653986, # of mesh vertices: 30378, # of mesh faces: 60846\n",
      "Iteration 2100 - loss: 0.0014044517884030938, # of mesh vertices: 31797, # of mesh faces: 63766\n",
      "Iteration 2200 - loss: 0.001377988955937326, # of mesh vertices: 30061, # of mesh faces: 60178\n",
      "Iteration 2300 - loss: 0.0016906415112316608, # of mesh vertices: 31810, # of mesh faces: 63780\n",
      "Iteration 2400 - loss: 0.0020804577507078648, # of mesh vertices: 32501, # of mesh faces: 65190\n",
      "Iteration 2500 - loss: 0.0015246992697939277, # of mesh vertices: 29711, # of mesh faces: 59464\n",
      "Iteration 2600 - loss: 0.0017032924806699157, # of mesh vertices: 33456, # of mesh faces: 67180\n",
      "Iteration 2700 - loss: 0.0014160431455820799, # of mesh vertices: 31096, # of mesh faces: 62294\n",
      "Iteration 2800 - loss: 0.0014446306740865111, # of mesh vertices: 31167, # of mesh faces: 62480\n",
      "Iteration 2900 - loss: 0.0014883755939081311, # of mesh vertices: 31361, # of mesh faces: 62822\n",
      "Iteration 3000 - loss: 0.0016157212667167187, # of mesh vertices: 32147, # of mesh faces: 64564\n",
      "Iteration 3100 - loss: 0.0016537777846679091, # of mesh vertices: 33434, # of mesh faces: 67244\n",
      "Iteration 3200 - loss: 0.0017736820736899972, # of mesh vertices: 28195, # of mesh faces: 56152\n",
      "Iteration 3300 - loss: 0.0017201164737343788, # of mesh vertices: 32680, # of mesh faces: 65714\n",
      "Iteration 3400 - loss: 0.0018111597746610641, # of mesh vertices: 33323, # of mesh faces: 67032\n",
      "Iteration 3500 - loss: 0.0018456514226272702, # of mesh vertices: 34286, # of mesh faces: 68956\n",
      "Iteration 3600 - loss: 0.0017207477940246463, # of mesh vertices: 31354, # of mesh faces: 62760\n",
      "Iteration 3700 - loss: 0.0018540521850809455, # of mesh vertices: 34309, # of mesh faces: 69028\n",
      "Iteration 3800 - loss: 0.0017429275903850794, # of mesh vertices: 33156, # of mesh faces: 66614\n",
      "Iteration 3900 - loss: 0.0017029711743816733, # of mesh vertices: 33788, # of mesh faces: 67976\n",
      "Iteration 4000 - loss: 0.0018446475733071566, # of mesh vertices: 32279, # of mesh faces: 64598\n",
      "Iteration 4100 - loss: 0.0018163545755669475, # of mesh vertices: 32692, # of mesh faces: 65558\n",
      "Iteration 4200 - loss: 0.0018794562201946974, # of mesh vertices: 34521, # of mesh faces: 69432\n",
      "Iteration 4300 - loss: 0.0018229588167741895, # of mesh vertices: 33648, # of mesh faces: 67550\n",
      "Iteration 4400 - loss: 0.001927110948599875, # of mesh vertices: 34822, # of mesh faces: 69934\n",
      "Iteration 4500 - loss: 0.001904618926346302, # of mesh vertices: 35072, # of mesh faces: 70414\n",
      "Iteration 4600 - loss: 0.0018560761818662286, # of mesh vertices: 34619, # of mesh faces: 69596\n",
      "Iteration 4700 - loss: 0.0019440255127847195, # of mesh vertices: 33892, # of mesh faces: 68018\n",
      "Iteration 4800 - loss: 0.0018472301308065653, # of mesh vertices: 34608, # of mesh faces: 69580\n",
      "Iteration 4900 - loss: 0.0019176941132172942, # of mesh vertices: 34276, # of mesh faces: 68920\n",
      "Iteration 5000 - loss: 0.0019050942501053214, # of mesh vertices: 32287, # of mesh faces: 64572\n",
      "Iteration 5100 - loss: 0.0019782178569585085, # of mesh vertices: 33859, # of mesh faces: 67924\n",
      "Iteration 5200 - loss: 0.0020078851375728846, # of mesh vertices: 34965, # of mesh faces: 70262\n",
      "Iteration 5300 - loss: 0.002087547443807125, # of mesh vertices: 35262, # of mesh faces: 70864\n",
      "Iteration 5400 - loss: 0.0020089324098080397, # of mesh vertices: 34492, # of mesh faces: 69268\n",
      "Iteration 5500 - loss: 0.0022134929895401, # of mesh vertices: 34549, # of mesh faces: 69398\n",
      "Iteration 5600 - loss: 0.0019890819676220417, # of mesh vertices: 34009, # of mesh faces: 68300\n",
      "Iteration 5700 - loss: 0.002149092499166727, # of mesh vertices: 34455, # of mesh faces: 69238\n",
      "Iteration 5800 - loss: 0.0020494067575782537, # of mesh vertices: 34360, # of mesh faces: 68996\n",
      "Iteration 5900 - loss: 0.0021742298267781734, # of mesh vertices: 33971, # of mesh faces: 68172\n",
      "Iteration 6000 - loss: 0.0021403818391263485, # of mesh vertices: 34742, # of mesh faces: 69786\n",
      "Iteration 6100 - loss: 0.002099414588883519, # of mesh vertices: 34971, # of mesh faces: 70384\n",
      "Iteration 6200 - loss: 0.002080013509839773, # of mesh vertices: 34713, # of mesh faces: 69836\n",
      "Iteration 6300 - loss: 0.0020187688060104847, # of mesh vertices: 33846, # of mesh faces: 67936\n",
      "Iteration 6400 - loss: 0.0019626386929303408, # of mesh vertices: 33700, # of mesh faces: 67666\n",
      "Iteration 6500 - loss: 0.0020150416530668736, # of mesh vertices: 34392, # of mesh faces: 69162\n",
      "Iteration 6600 - loss: 0.0020203334279358387, # of mesh vertices: 34642, # of mesh faces: 69666\n",
      "Iteration 6700 - loss: 0.0020124816801398993, # of mesh vertices: 34405, # of mesh faces: 69148\n",
      "Iteration 6800 - loss: 0.0020991929341107607, # of mesh vertices: 34852, # of mesh faces: 70140\n",
      "Iteration 6900 - loss: 0.0020691619720309973, # of mesh vertices: 34947, # of mesh faces: 70304\n",
      "Iteration 7000 - loss: 0.0021136163268238306, # of mesh vertices: 34074, # of mesh faces: 68368\n",
      "Iteration 7100 - loss: 0.0020319942850619555, # of mesh vertices: 34906, # of mesh faces: 70186\n",
      "Iteration 7200 - loss: 0.002053921576589346, # of mesh vertices: 35101, # of mesh faces: 70606\n",
      "Iteration 7300 - loss: 0.0020362110808491707, # of mesh vertices: 34625, # of mesh faces: 69588\n",
      "Iteration 7400 - loss: 0.002048812573775649, # of mesh vertices: 34911, # of mesh faces: 70208\n",
      "Iteration 7500 - loss: 0.0020672616083174944, # of mesh vertices: 34314, # of mesh faces: 69032\n",
      "Iteration 7600 - loss: 0.0020702064502984285, # of mesh vertices: 34484, # of mesh faces: 69356\n",
      "Iteration 7700 - loss: 0.002101516118273139, # of mesh vertices: 34799, # of mesh faces: 70006\n",
      "Iteration 7800 - loss: 0.002050182782113552, # of mesh vertices: 35188, # of mesh faces: 70806\n",
      "Iteration 7900 - loss: 0.002061321632936597, # of mesh vertices: 34983, # of mesh faces: 70316\n",
      "Iteration 8000 - loss: 0.0021266357507556677, # of mesh vertices: 34718, # of mesh faces: 69764\n",
      "Iteration 8100 - loss: 0.002039831830188632, # of mesh vertices: 34594, # of mesh faces: 69468\n",
      "Iteration 8200 - loss: 0.002154179848730564, # of mesh vertices: 34906, # of mesh faces: 70154\n",
      "Iteration 8300 - loss: 0.0020481871906667948, # of mesh vertices: 34930, # of mesh faces: 70224\n",
      "Iteration 8400 - loss: 0.0021407923195511103, # of mesh vertices: 34956, # of mesh faces: 70234\n",
      "Iteration 8500 - loss: 0.0020320676267147064, # of mesh vertices: 34943, # of mesh faces: 70208\n",
      "Iteration 8600 - loss: 0.002124025719240308, # of mesh vertices: 34905, # of mesh faces: 70128\n",
      "Iteration 8700 - loss: 0.002076930832117796, # of mesh vertices: 34561, # of mesh faces: 69388\n",
      "Iteration 8800 - loss: 0.0021371841430664062, # of mesh vertices: 34599, # of mesh faces: 69476\n",
      "Iteration 8900 - loss: 0.002105986699461937, # of mesh vertices: 34849, # of mesh faces: 69944\n",
      "Iteration 9000 - loss: 0.0019977313932031393, # of mesh vertices: 30896, # of mesh faces: 61500\n",
      "Iteration 9100 - loss: 0.002003077417612076, # of mesh vertices: 34962, # of mesh faces: 70278\n",
      "Iteration 9200 - loss: 0.0020806428510695696, # of mesh vertices: 35065, # of mesh faces: 70464\n",
      "Iteration 9300 - loss: 0.0021081597078591585, # of mesh vertices: 34886, # of mesh faces: 70030\n",
      "Iteration 9400 - loss: 0.002030827570706606, # of mesh vertices: 34951, # of mesh faces: 70200\n",
      "Iteration 9500 - loss: 0.0020933670457452536, # of mesh vertices: 34792, # of mesh faces: 69822\n",
      "Iteration 9600 - loss: 0.0021221148781478405, # of mesh vertices: 34781, # of mesh faces: 69786\n",
      "Iteration 9700 - loss: 0.0021226562093943357, # of mesh vertices: 35141, # of mesh faces: 70534\n",
      "Iteration 9800 - loss: 0.0020473257172852755, # of mesh vertices: 35154, # of mesh faces: 70590\n",
      "Iteration 9900 - loss: 0.002134285867214203, # of mesh vertices: 35036, # of mesh faces: 70352\n",
      "Iteration 9999 - loss: 0.002142569050192833, # of mesh vertices: 34402, # of mesh faces: 69004\n"
     ]
    }
   ],
   "source": [
    "for it in range(iterations):\n",
    "    pred = model(tet_verts) # predict SDF and per-vertex deformation\n",
    "    sdf, deform = pred[:,0], pred[:,1:]\n",
    "    verts_deformed = tet_verts + torch.tanh(deform) / grid_res # constraint deformation to avoid flipping tets\n",
    "    mesh_verts, mesh_faces = kaolin.ops.conversions.marching_tetrahedra(verts_deformed.unsqueeze(0), tets, sdf.unsqueeze(0)) # running MT (batched) to extract surface mesh\n",
    "    #print(mesh_verts, mesh_faces)\n",
    "    mesh_verts, mesh_faces = mesh_verts[0], mesh_faces[0]\n",
    "\n",
    "    loss = loss_f(mesh_verts, mesh_faces, points, it)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    if (it) % save_every == 0 or it == (iterations - 1): \n",
    "        print ('Iteration {} - loss: {}, # of mesh vertices: {}, # of mesh faces: {}'.format(it, loss, mesh_verts.shape[0], mesh_faces.shape[0]))\n",
    "        # save reconstructed mesh\n",
    "        timelapse.add_mesh_batch(\n",
    "            iteration=it+1,\n",
    "            category='extracted_mesh',\n",
    "            vertices_list=[mesh_verts.cpu()],\n",
    "            faces_list=[mesh_faces.cpu()]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1501,  0.1312, -0.0160],\n",
       "        [ 0.0748,  0.1856, -0.0396],\n",
       "        [ 0.1481,  0.3223, -0.0360],\n",
       "        ...,\n",
       "        [ 0.3628,  0.2961, -0.0100],\n",
       "        [ 0.2895,  0.2162,  0.0100],\n",
       "        [-0.0581,  0.1527,  0.0432]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from point_e.util.point_cloud import PointCloud\n",
    "pc = PointCloud.load('example_data/pc_012.npz')\n",
    "torch.tensor(pc.coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eliminate KAOLIN library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from point_e.util.point_cloud import PointCloud\n",
    "import torch\n",
    "\n",
    "# arguments and hyperparameters\n",
    "device = 'cuda'\n",
    "lr = 1e-3\n",
    "laplacian_weight = 0.8\n",
    "iterations = 10000\n",
    "save_every = 100\n",
    "multires = 8\n",
    "grid_res = 128\n",
    "\n",
    "pc_data = 'example_data/pc_012.npz'\n",
    "#pc_data = 'example_data/pc_corgi.npz'\n",
    "pc = PointCloud.load(pc_data)\n",
    "points = pc.coords\n",
    "#pcd_path = \"/home/ubuntu/point-e/point_e/util/dmtet/usd/bear_pointcloud.usd\"\n",
    "#points = kaolin.io.usd.import_pointclouds(pcd_path)[0].points.to(device)\n",
    "\n",
    "center = (points.max(0)[0] + points.min(0)[0]) / 2\n",
    "max_l = (points.max(0)[0] - points.min(0)[0]).max()\n",
    "points = ((points - center) / max_l)* 0.9\n",
    "points = torch.tensor(points).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dynamic module does not define module export function (PyInit__C)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpoint_e\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdmtet\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdmtet_network\u001b[39;00m \u001b[39mimport\u001b[39;00m Decoder\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/point-e/point_e/util/dmtet/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtrianglemesh\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpointcloud\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtetmesh\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/point-e/point_e/util/dmtet/pointcloud.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpoint_e\u001b[39;00m \u001b[39mimport\u001b[39;00m _C\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mchamfer_distance\u001b[39m(p1, p2, w1\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m, w2\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m, squared\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m      5\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Computes the chamfer distance between two pointclouds, defined as following:\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m    :math:`\\dfrac{w_1}{|P_1|}\\sum\\limits_{p_{1i} \\in P_1}\\min\\limits_{p_{2j} \\in P_2}(||p_{1i} - p_{2j}||_2^2) +\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m    \\dfrac{w_2}{|P_2|}\\sum\\limits_{p_{2j} \\in P_2}\\min\\limits_{p_{1i} \\in P_1}(||p_{2j} - p_{1i}||_2^2)`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m        tensor([ 72.5838, 151.0809], device='cuda:0')\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: dynamic module does not define module export function (PyInit__C)"
     ]
    }
   ],
   "source": [
    "from point_e.util.dmtet.dmtet_network import Decoder\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "tet_verts = torch.tensor(np.load('/home/ubuntu/point-e/point_e/util/dmtet/samples/{}_verts.npz'.format(grid_res))['data'], dtype=torch.float, device=device)\n",
    "tets = torch.tensor(([np.load('/home/ubuntu/point-e/point_e/util/dmtet/samples/{}_tets_{}.npz'.format(grid_res, i))['data'] for i in range(4)]), dtype=torch.long, device=device).permute(1,0)\n",
    "print(tet_verts.shape, tets.shape)\n",
    "\n",
    "# Initialize model and create optimizer\n",
    "model = Decoder(multires=multires).to(device)\n",
    "model.pre_train_sphere(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian regularization using umbrella operator (Fujiwara / Desbrun).\n",
    "# https://mgarland.org/class/geom04/material/smoothing.pdf\n",
    "import kaolin\n",
    "import point_e\n",
    "\n",
    "def laplace_regularizer_const(mesh_verts, mesh_faces):\n",
    "    term = torch.zeros_like(mesh_verts)\n",
    "    norm = torch.zeros_like(mesh_verts[..., 0:1])\n",
    "\n",
    "    v0 = mesh_verts[mesh_faces[:, 0], :]\n",
    "    v1 = mesh_verts[mesh_faces[:, 1], :]\n",
    "    v2 = mesh_verts[mesh_faces[:, 2], :]\n",
    "\n",
    "    term.scatter_add_(0, mesh_faces[:, 0:1].repeat(1,3), (v1 - v0) + (v2 - v0))\n",
    "    term.scatter_add_(0, mesh_faces[:, 1:2].repeat(1,3), (v0 - v1) + (v2 - v1))\n",
    "    term.scatter_add_(0, mesh_faces[:, 2:3].repeat(1,3), (v0 - v2) + (v1 - v2))\n",
    "\n",
    "    two = torch.ones_like(v0) * 2.0\n",
    "    norm.scatter_add_(0, mesh_faces[:, 0:1], two)\n",
    "    norm.scatter_add_(0, mesh_faces[:, 1:2], two)\n",
    "    norm.scatter_add_(0, mesh_faces[:, 2:3], two)\n",
    "\n",
    "    term = term / torch.clamp(norm, min=1.0)\n",
    "\n",
    "    return torch.mean(term**2)\n",
    "\n",
    "def loss_f(mesh_verts, mesh_faces, points, it):\n",
    "    pred_points = point_e.util.dmtet.trianglemesh.sample_points(mesh_verts.unsqueeze(0), mesh_faces, 50000)[0][0]\n",
    "    chamfer = point_e.util.dmtet.pointcloud.chamfer_distance(pred_points.unsqueeze(0), points.unsqueeze(0)).mean()\n",
    "    if it > iterations//2:\n",
    "        lap = laplace_regularizer_const(mesh_verts, mesh_faces)\n",
    "        return chamfer + lap * laplacian_weight\n",
    "    return chamfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mvars\u001b[39m \u001b[39m=\u001b[39m [p \u001b[39mfor\u001b[39;00m _, p \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mnamed_parameters()]\n\u001b[1;32m      2\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(\u001b[39mvars\u001b[39m, lr\u001b[39m=\u001b[39mlr)\n\u001b[1;32m      3\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mLambdaLR(optimizer, lr_lambda\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: \u001b[39mmax\u001b[39m(\u001b[39m0.0\u001b[39m, \u001b[39m10\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(\u001b[39m-\u001b[39mx\u001b[39m*\u001b[39m\u001b[39m0.0002\u001b[39m))) \u001b[39m# LR decay over time\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "vars = [p for _, p in model.named_parameters()]\n",
    "optimizer = torch.optim.Adam(vars, lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time\n",
    "\n",
    "logs_path = './logs'\n",
    "\n",
    "# We initialize the timelapse that will store USD for the visualization apps\n",
    "#timelapse = kaolin.visualize.Timelapse(logs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m it \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(iterations):\n\u001b[0;32m----> 2\u001b[0m     pred \u001b[39m=\u001b[39m model(tet_verts) \u001b[39m# predict SDF and per-vertex deformation\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     sdf, deform \u001b[39m=\u001b[39m pred[:,\u001b[39m0\u001b[39m], pred[:,\u001b[39m1\u001b[39m:]\n\u001b[1;32m      4\u001b[0m     verts_deformed \u001b[39m=\u001b[39m tet_verts \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mtanh(deform) \u001b[39m/\u001b[39m grid_res \u001b[39m# constraint deformation to avoid flipping tets\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "for it in range(iterations):\n",
    "    pred = model(tet_verts) # predict SDF and per-vertex deformation\n",
    "    sdf, deform = pred[:,0], pred[:,1:]\n",
    "    verts_deformed = tet_verts + torch.tanh(deform) / grid_res # constraint deformation to avoid flipping tets\n",
    "    mesh_verts, mesh_faces = point_e.util.dmtet.tetmesh.marching_tetrahedra(verts_deformed.unsqueeze(0), tets, sdf.unsqueeze(0)) # running MT (batched) to extract surface mesh\n",
    "    #print(mesh_verts, mesh_faces)\n",
    "    mesh_verts, mesh_faces = mesh_verts[0], mesh_faces[0]\n",
    "\n",
    "    loss = loss_f(mesh_verts, mesh_faces, points, it)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    if (it) % save_every == 0 or it == (iterations - 1): \n",
    "        print ('Iteration {} - loss: {}, # of mesh vertices: {}, # of mesh faces: {}'.format(it, loss, mesh_verts.shape[0], mesh_faces.shape[0]))\n",
    "        # save reconstructed mesh\n",
    "        # timelapse.add_mesh_batch(\n",
    "        #     iteration=it+1,\n",
    "        #     category='extracted_mesh',\n",
    "        #     vertices_list=[mesh_verts.cpu()],\n",
    "        #     faces_list=[mesh_faces.cpu()]\n",
    "        # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "dfd2c728a2bccd8159f0d1af1e08785e078f935dba676028c3382e473521f403"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
